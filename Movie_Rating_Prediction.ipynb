{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_rating.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWggPUcrsaXEQxJkSsZliO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi789789/My-Projects/blob/master/Movie_rating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmSxu1WeJfze",
        "colab_type": "code",
        "outputId": "61137dae-1e33-40e2-8cec-ebac85cc46a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHhJBb4KdxT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "train_df=pd.read_csv(\"/content/gdrive/My Drive/movie_rev_Train.csv\")\n",
        "test_df=pd.read_csv(\"/content/gdrive/My Drive/MovieTest.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i97uvsjalqXG",
        "colab_type": "code",
        "outputId": "b985b7c6-5006-4b80-c7c7-5fd56c671d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xtr=train_df['review']\n",
        "ytr=train_df['label']\n",
        "xte=test_df['review']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "ytr=le.fit_transform(ytr)\n",
        "print(ytr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P98QtFvaZIr",
        "colab_type": "code",
        "outputId": "28f8916c-314d-456b-c57d-34e38c4e46a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ5RC_WdLvNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgCZ_k8GefMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating A Function To Process Data(Tokenizing,stopwards_removal,stemming)\n",
        "def get_stemmed_reviw(review):\n",
        "    review=review.lower()\n",
        "    tokenizer=RegexpTokenizer(r'\\w+')\n",
        "    token=tokenizer.tokenize(review)\n",
        "    en_stopwars=set(stopwords.words('english'))\n",
        "    en_stopwars.remove('not')\n",
        "    new_token=[token for token in token if token not in en_stopwars]\n",
        "    ps=PorterStemmer()\n",
        "    stem_tokn=[ps.stem(token)for token in new_token]\n",
        "    clean_review=' '.join(stem_tokn)\n",
        "    return(clean_review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBgFlA2YovJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Taking Processed Train_data in p and Processed Test_data in q\n",
        "p=[get_stemmed_reviw(i) for i in xtr]\n",
        "q=[get_stemmed_reviw(i) for i in xte]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSvxY_0yfzy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GheH-pTkYNaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.core import Activation,Dropout,Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Conv1D,LSTM,GlobalMaxPooling1D,SimpleRNN,Flatten,Bidirectional,MaxPool1D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSrHKIz2e7n_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting each traning word in tokenizer so as to create embedding matrix later\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(p)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya2h9zspf6sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting textual data in numeric form(both traning and testing data)\n",
        "p= tokenizer.texts_to_sequences(p)\n",
        "q= tokenizer.texts_to_sequences(q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lqPxOR0fAKo",
        "colab_type": "code",
        "outputId": "5e970afb-8689-4938-e44f-6029436716d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgkvQD1jfE2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "maxlen=300\n",
        "p = pad_sequences(p, padding='post', maxlen=maxlen)\n",
        "q = pad_sequences(q, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnxrgpO1gCz9",
        "colab_type": "code",
        "outputId": "90298bef-85fd-4dcb-95df-6ddc8e152c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1823,   638,   475, ...,     0,     0,     0],\n",
              "       [ 4856,   287,  8458, ...,     0,     0,     0],\n",
              "       [   69,   713,   702, ..., 11020,   153,   397],\n",
              "       ...,\n",
              "       [   21,   305,   460, ...,     0,     0,     0],\n",
              "       [ 7666,   322,  1024, ...,     0,     0,     0],\n",
              "       [  132,     2, 14622, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZgvLKjHcG4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/gdrive/My Drive/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwQqFKt1dmSK",
        "colab_type": "code",
        "outputId": "919c7590-fc8b-422b-fb3d-87bd4681e691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#using transfer learning to train the model\n",
        "import gensim\n",
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True, limit=100000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzUQz8Nnl24A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a embedding matrix witht he help of google word2vec\n",
        "embedding_weights = np.zeros((vocab_size, 300))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    #embedding_vector = word2vec.get(word)\n",
        "    try:\n",
        "        embedding_weights[index] = word2vec[word]\n",
        "    except:\n",
        "        pass "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJIz-qJ4cVc6",
        "colab_type": "code",
        "outputId": "7a727f67-bd8c-4cff-b56f-6fc89e94b7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65665, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJJSGlYl72P",
        "colab_type": "code",
        "outputId": "94e5d49f-9b3b-4fea-afef-28859e21a3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(word2vec['china'][:40])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.29492188  0.08447266  0.01031494  0.34570312 -0.09375     0.05541992\n",
            "  0.13183594 -0.2734375  -0.11816406  0.3125     -0.296875   -0.36914062\n",
            "  0.10058594 -0.1796875  -0.16894531  0.11279297 -0.12255859  0.27539062\n",
            " -0.21582031 -0.453125    0.09472656 -0.16113281  0.3203125  -0.328125\n",
            "  0.17382812  0.59765625 -0.22070312  0.19335938 -0.04467773 -0.0625\n",
            " -0.13476562 -0.10791016 -0.31445312 -0.05151367 -0.09619141 -0.15625\n",
            " -0.23828125  0.01611328  0.00613403  0.08203125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP2NM4EkML4t",
        "colab_type": "code",
        "outputId": "8e89129e-f8ab-4301-b81b-f3c3a0b49dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "from keras.regularizers import l2\n",
        "model=Sequential()\n",
        "em_layer=Embedding(vocab_size,300,weights=[embedding_weights],input_length=300,trainable=False)\n",
        "model.add(em_layer)\n",
        "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 300, 300)          19699500  \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 298, 256)          230656    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 19,930,413\n",
            "Trainable params: 230,913\n",
            "Non-trainable params: 19,699,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INIISTbiObq1",
        "colab_type": "code",
        "outputId": "96ed92d6-6a2e-4753-e36a-45847af3327f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EarlyStopping(monitor='val_acc',\n",
        "                              min_delta=0,\n",
        "                              patience=1,\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.EarlyStopping at 0x7f7cdb826278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gw0_rEQ89I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYEw4_rntXbx",
        "colab_type": "code",
        "outputId": "e61af623-3195-4f89-d357-4e377bb7708e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "history = model.fit(p, ytr, batch_size=60, epochs=15, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/15\n",
            "32000/32000 [==============================] - 10s 318us/step - loss: 0.4357 - accuracy: 0.7940 - val_loss: 0.3564 - val_accuracy: 0.8435\n",
            "Epoch 2/15\n",
            "32000/32000 [==============================] - 10s 308us/step - loss: 0.3306 - accuracy: 0.8566 - val_loss: 0.3253 - val_accuracy: 0.8586\n",
            "Epoch 3/15\n",
            "32000/32000 [==============================] - 10s 309us/step - loss: 0.2853 - accuracy: 0.8798 - val_loss: 0.3069 - val_accuracy: 0.8691\n",
            "Epoch 4/15\n",
            "32000/32000 [==============================] - 10s 307us/step - loss: 0.2438 - accuracy: 0.9013 - val_loss: 0.3153 - val_accuracy: 0.8609\n",
            "Epoch 5/15\n",
            "32000/32000 [==============================] - 10s 308us/step - loss: 0.2197 - accuracy: 0.9128 - val_loss: 0.3030 - val_accuracy: 0.8737\n",
            "Epoch 6/15\n",
            "32000/32000 [==============================] - 10s 306us/step - loss: 0.1871 - accuracy: 0.9276 - val_loss: 0.3012 - val_accuracy: 0.8744\n",
            "Epoch 7/15\n",
            "32000/32000 [==============================] - 10s 306us/step - loss: 0.1630 - accuracy: 0.9375 - val_loss: 0.3054 - val_accuracy: 0.8741\n",
            "Epoch 8/15\n",
            "32000/32000 [==============================] - 10s 307us/step - loss: 0.1419 - accuracy: 0.9470 - val_loss: 0.3129 - val_accuracy: 0.8752\n",
            "Epoch 9/15\n",
            "32000/32000 [==============================] - 10s 306us/step - loss: 0.1217 - accuracy: 0.9551 - val_loss: 0.3217 - val_accuracy: 0.8708\n",
            "Epoch 10/15\n",
            "32000/32000 [==============================] - 10s 305us/step - loss: 0.1067 - accuracy: 0.9620 - val_loss: 0.3273 - val_accuracy: 0.8742\n",
            "Epoch 11/15\n",
            "32000/32000 [==============================] - 10s 309us/step - loss: 0.0935 - accuracy: 0.9676 - val_loss: 0.3440 - val_accuracy: 0.8724\n",
            "Epoch 12/15\n",
            "32000/32000 [==============================] - 10s 310us/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 0.3455 - val_accuracy: 0.8742\n",
            "Epoch 13/15\n",
            "32000/32000 [==============================] - 10s 307us/step - loss: 0.0736 - accuracy: 0.9752 - val_loss: 0.3571 - val_accuracy: 0.8745\n",
            "Epoch 14/15\n",
            "32000/32000 [==============================] - 10s 307us/step - loss: 0.0706 - accuracy: 0.9749 - val_loss: 0.3651 - val_accuracy: 0.8729\n",
            "Epoch 15/15\n",
            "32000/32000 [==============================] - 10s 306us/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.3716 - val_accuracy: 0.8708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlTTeVAb2LDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans=model.predict_classes(q)\n",
        "ans=le.inverse_transform(ans)\n",
        "movie=pd.DataFrame()\n",
        "path=pd.read_csv(\"/content/gdrive/My Drive/Sample_submission.csv\")\n",
        "l=path['Id']\n",
        "movie['Id']=l\n",
        "movie['label']=ans\n",
        "movie.to_csv(\"solution_movie5.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
